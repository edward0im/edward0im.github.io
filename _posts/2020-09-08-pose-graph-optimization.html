--- 
layout: post
title: (SLAM) Notes on Pose Graph Optimization with codes
description: 
date: 2020-09-08
categories: [Engineering]
tag: [Engineering, SLAM, Pose Graph, Optimization, Loop Closing, Nonlinear Least Square]
use_math: true
comments: true
---
<nav id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org0e830e1">1. Introduction</a></li>
<li><a href="#orge3b3fc5">2. Pose graph</a></li>
<li><a href="#org0299799">3. Pose graph optimization</a>
<ul>
<li><a href="#orgf0bbaad">3.1. Nonlinear least square method</a></li>
<li><a href="#org510ea51">3.2. Graphical explain of PGO</a></li>
</ul>
</li>
<li><a href="#org33ba380">4. Code review</a></li>
<li><a href="#org1c08706">5. References</a></li>
</ul>
</div>
</nav>


<div id="outline-container-org0e830e1" class="outline-2">
<h2 id="org0e830e1"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
로봇이 SLAM을 수행하는 동안 센서 데이터가 입력으로 들어오는데 순차적으로 들어오는 센서 데이터들의 차이를 통해 로봇의 포즈를 계산하는 알고리즘을 <b>Odometry</b> 또는 <b>Front-end</b> 라고 한다. 이 때, 센서 데이터의 노이즈로 인해 Odometry는 필연적으로 에러를 포함하고 있는데 시간이 지날수록 에러는 누적되어 전체적인 Trajectroy가 어긋나게 된다. 이러한 문제를 해결하기 위해 1997년 Lu and Milios는 로봇의 포즈를 그래프 자료구조로 표현함으로써 최적화하는 GraphSLAM 방법을 제안하였다<a href="#org1c08706">(1)</a>.
</p>

<p>
GraphSLAM의 Pipeline은 크게 Front-end와 Back-end로 구분할 수 있는데 로봇의 센서를 입력으로 받아 Pose Graph를 생성하는 부분을 Front-end라고 부르며 Front-end는 시간이 지날수록 노이즈로 인한 에러가 누적된다. 이렇게 <b>누적된 에러를 최적화하는 부분을 Back-end라고 부르며 이 때 사용하는 알고리즘을 Pose Graph Optimization (PGO)</b> 라고 한다. PGO는 로봇의 포즈만 변경시키고 맵 상에 존재하는 맵포인트들은 최적화하지 않는다. PGO와 달리 <b>로봇의 포즈와 맵포인트를 동시에 최적화하는 방법을 Bundle Adjustment</b> 라고 한다. 해당 포스트에서는 PGO만을 다룬다.
</p>


<figure>
<img src="/pictures/200908/01.png" alt="01.png" align="center" width="500px">

<figcaption><span class="figure-number">Figure 1: </span>Pose Graph-based SLAM System Pipeline. The image is from the freiburg university Robot Mapping lecture.</figcaption>
</figure>
</div>
</div>

<div id="outline-container-orge3b3fc5" class="outline-2">
<h2 id="orge3b3fc5"><span class="section-number-2">2</span> Pose graph</h2>
<div class="outline-text-2" id="text-2">
<p>
Pose Graph는 로봇의 포즈를 자료구조 중 하나인 그래프로 표현한 SLAM에 특화된 자료구조를 의미한다. <b>Pose Graph에서 노드는 로봇의 포즈(Pose)로 나타내고 엣지는 노드 사이의 상대 포즈(Relative Pose)로 나타낸다.</b> 아래 그림은 Graph와 Pose Graph 자료구조의 차이점을 나타낸 그림이다.
</p>


<figure>
<img src="/pictures/200908/02.png" alt="02.png" align="center">

</figure>

<p>
본 포스팅에서는 3차원 SLAM에 관한 내용을 다루므로 Pose Graph에서 Pose $\mathbf{x}$와 Edge $\mathbf{z}$는 다음과 같이 정의된다.
</p>


<figure>
<img src="/pictures/200908/03.png" alt="03.png" align="center" width="300px">

</figure>

\begin{equation}
\begin{aligned}
\text{(Node) } \mathbf{x}_{i} &amp; = [x_{i} \ \  y_{i} \ \  z_{i} \ \  \alpha_{i} \ \  \beta_{i} \ \  \gamma_{i}]^{\intercal} \\
&amp; = \begin{bmatrix} \mathbf{R}_{i} &amp; \mathbf{t}_{i} \\ \mathbf{0} &amp; 1 \end{bmatrix}_{4\times 4}
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\text{(Edge) } \mathbf{z}_{ij} &amp; = [x_{ij} \ \  y_{ij} \ \  z_{ij} \ \  \alpha_{ij} \ \  \beta_{ij} \ \  \gamma_{ij}]^{\intercal} \\
&amp; = \begin{bmatrix} \mathbf{R}_{ij} &amp; \mathbf{t}_{ij} \\ \mathbf{0} &amp; 1 \end{bmatrix}_{4\times 4} \\ 
\end{aligned}
\end{equation}
<p>
이 때, $\mathbf{x}_{i}$는 i번째 포즈를 의미하며 $\mathbf{z}_{ij}$는 노드 i,j 사이의 상대포즈를 의미한다.
</p>
</div>
</div>

<div id="outline-container-org0299799" class="outline-2">
<h2 id="org0299799"><span class="section-number-2">3</span> Pose graph optimization</h2>
<div class="outline-text-2" id="text-3">
<p>
Loop Closing과 같은 특수한 상황이 발생하면 Front-end에서 에러가 누적된 모든 노드와 엣지 정보를 Back-end로 전달하고 Back-end에서는 Pose Graph Optimizatino을 통해 에러가 최소가 되도록 모든 노드들의 위치를 최적화하는 과정을 수행한다. 이를 단계별로 정리하면 다음과 같다.
</p>

<ul class="org-ul">
<li>Loop Closing과 같은 특수한 상황 발생</li>
<li>Front-end에서 GICP와 같은 방법을 통해 노드들의 관측값을 업데이트 (업데이트 전의 값들은 예측값으로 설정)</li>
<li>Front-end에서 현재까지 에러가 누적된 모든 노드들과 엣지 정보를 Back-end로 전달</li>
<li>Back-end에서 관측값과 예측값의 차이, 즉 에러가 최소가 되는 방향으로 에러함수를 최적화</li>
</ul>

<p>
이러한 과정을 Pose Graph Optimization (PGO)라고 하며 공식으로 표현하면 다음과 같다.
</p>

\begin{equation}
\begin{aligned}
\mathbf{x}^{*} = \arg\min_{\mathbf{x}} \| \mathbf{z} -  \hat{\mathbf{z}} \|^{2}_{\Sigma} = \| \mathbf{e} \|_{\Sigma}^{2}
\end{aligned}
\end{equation}
<p>
이 때, $\mathbf{x}= \begin{bmatrix}\mathbf{x}_{1} &amp; &ctdot; &amp; \mathbf{x}_{i} &amp; &ctdot; &amp; \mathbf{x}_{n}\end{bmatrix}^{\intercal}$는 로봇의 포즈 벡터를 의미하고 각각의 Pose 노드는 다음과 같다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{x}_{i} = \begin{bmatrix}
\mathbf{R}_{i} &amp; \mathbf{t}_{i} \\ 
0 &amp; 1
\end{bmatrix} \in \mathbb{R}^{4\times4}
\end{aligned}
\end{equation}
<p>
그리고 $\mathbf{z}$는 두 노드 사이의 GICP를 통해 업데이트된 상대포즈(관측값)을 의미하고 $\hat{\mathbf{z}}$는 두 노드 사이의 업데이트 전 상대포즈(예측값)을 의미한다. 관측값과 예측값의 차이를 에러함수 $\mathbf{e}$로 정의한다. 그리고 $\| \mathbf{e}\|_{&Sigma;}^{2}=\mathbf{e}^{\intercal}&Sigma;^{-1}\mathbf{e}=\mathbf{e}^{\intercal}&Omega; \mathbf{e}$를 의미한다.
</p>

<p>
PGO 공식을 순차적인 노드와 비순차적인 노드로 분리하면 다음과 같이 나타낼 수 있다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{x}^{*} = \arg\min_{\mathbf{x}} \sum_{i} \left \| \mathbf{z}_{i,i+1} -  \hat{\mathbf{z}}_{i,i+1} \right \|^{2}_{\Sigma_{i,i+1}} 
+ \sum_{i,j} \left \| \mathbf{z}_{i,j} - \hat{\mathbf{z}}_{i,j} \right \|^{2}_{\Sigma_{i,j}}
\end{aligned}
\end{equation}
<p>
이 때, $\mathbf{z}_{i,i+1}, \hat{\mathbf{z}}_{i,i+1}$은 순차적인 노드들 간 관측값 및 예측값을 의미하며 $\mathbf{z}_{i,j}, \hat{\mathbf{z}}_{i,j}$는 시간 순서와는 상관없는, 즉 비순차적인 노드들 간 관측값 및 예측값을 의미한다. 위 식을 에러함수로 간략하게 나타내면 다음과 같다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{x}^{*} = \arg\min_{\mathbf{x}} \sum_{i} (\mathbf{e}_{i,i+1}^{\intercal}\Omega_{i,i+1}\mathbf{e}_{i,i+1})
 + \sum_{ij} (\mathbf{e}_{ij}^{\intercal}\Omega_{ij}\mathbf{e}_{ij})
\end{aligned}
\end{equation}
<p>
이 때, 에러함수 $\mathbf{e}$는 회전과 관련된 $\cos, \sin$성분을 포함하고 있으므로 비선형성을 가진다. 따라서 <b>해당 공식은 한 번에 해를 구할 수 있는 closed form solution이 존재하지 않는다. 이러한 비선형 문제를 풀기 위해서는 Gauss-Newton(GN) 또는 Levenberg-Marquardt(LM)과 같은 비선형 최소제곱법을 사용해야 한다.</b>
</p>
</div>

<div id="outline-container-orgf0bbaad" class="outline-3">
<h3 id="orgf0bbaad"><span class="section-number-3">3.1</span> Nonlinear least square method</h3>
<div class="outline-text-3" id="text-3-1">
<p>
GN 방법을 사용해서 해당 문제를 푼다고 가정해보자. 에러함수 $\mathbf{e}_{ij}$를 자세히 나타내면 $\mathbf{e}_{ij}(\mathbf{x})$와 같고 이는 차량의 포즈 벡터 $\mathbf{x}$에 따라 에러함수의 값이 달라지는 것을 의미한다. GN 방법은 $\mathbf{e}(\mathbf{x})$에 반복적(iterative)으로 에러가 감소하는 방향으로 증분량 $&Delta; \mathbf{x}$를 업데이트한다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{e}_{ij}(\mathbf{x}+\Delta \mathbf{x})^{\intercal}\Omega_{ij}\mathbf{e}_{ij}(\mathbf{x}+\Delta \mathbf{x})
\end{aligned}
\end{equation}
<p>
이 때, $\mathbf{e}_{ij}(\mathbf{x}+&Delta; \mathbf{x})$를 $\Delta \mathbf{x} \rightarrow \mathbf{x}$부근에서 1차 테일러 전개를 사용하면 위 식은 다음과 같이 근사된다.
</p>

\begin{equation}
\begin{aligned}
\mathbf{e}_{ij}(\mathbf{x} + \Delta \mathbf{x}) \rvert_{\Delta \mathbf{x} \rightarrow \mathbf{x}} &amp; = \mathbf{e}_{ij}(\mathbf{x}) + \mathbf{J}_{ij}(\mathbf{x} + \Delta \mathbf{x} - \mathbf{x})\\
&amp; = \mathbf{e}_{ij}(\mathbf{x}) + \mathbf{J}_{ij}\Delta \mathbf{x}
\end{aligned}
\end{equation}
<p>
이 때, $\mathbf{J}_{ij} = \frac{&part; \mathbf{e}_{ij}(\mathbf{x}+ &Delta; \mathbf{x})}{&part; &Delta; \mathbf{x}}$이다. 이를 에러함수 전체에 적용하면 아래와 같다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{e}_{ij}(\mathbf{x}+\Delta \mathbf{x})^{\intercal}\Omega_{ij}\mathbf{e}_{ij}(\mathbf{x}+\Delta \mathbf{x}) \simeq (\mathbf{e}_{ij}+\mathbf{J}_{ij}\Delta \mathbf{x})^{\intercal}\Omega_{ij}
(\mathbf{e}_{ij}+\mathbf{J}_{ij}\Delta \mathbf{x})
\end{aligned}
\end{equation}
<p>
위 식을 전개한 후 치환하면 아래와 같다.
</p>

\begin{equation}
\begin{aligned}
&amp; = \underbrace{\mathbf{e}_{i}^{\intercal}\Omega_{ij}\mathbf{e}_{ij}}_{\mathbf{c}_{ij}} + 2 \underbrace{\mathbf{e}_{ij}^{\intercal}\Omega_{ij}\mathbf{J}_{ij}}_{\mathbf{b}_{ij}} \Delta \mathbf{x} + \Delta \mathbf{x}^{\intercal} \underbrace{\mathbf{J}_{ij}^{\intercal}\Omega_{ij}\mathbf{J}_{ij}}_{\mathbf{H}_{ij}} \Delta \mathbf{x} \\
&amp; = \mathbf{c}_{ij}+ 2\mathbf{b}_{ij}\Delta \mathbf{x} + \Delta \mathbf{x}^{\intercal} \mathbf{H}_{ij} \Delta \mathbf{x}
\end{aligned}
\end{equation}
<p>
위 식을 i,j 노드뿐만 아니라 전체 노드에 적용하면 다음과 같다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{E}(\mathbf{x}+\Delta \mathbf{x}) = \sum_{ij}\mathbf{e}_{ij}^{\intercal}\Omega_{ij}\mathbf{e}_{ij} = \mathbf{c}+ 2\mathbf{b}\Delta \mathbf{x} + \Delta \mathbf{x}^{T} \mathbf{H} \Delta \mathbf{x}
\end{aligned}
\end{equation}
<p>
$\mathbf{E}(\mathbf{x}+&Delta; \mathbf{x})$은 $&Delta; \mathbf{x}$에 대한 2차식(Quadratic) 형태이고 $\mathbf{H}= \mathbf{J}^{\intercal}&Omega; \mathbf{J}$는 positive definite 행렬이므로 <b>$\mathbf{E}(\mathbf{x}+ &Delta; \mathbf{x})$를 1차 미분하여 0으로 설정한 값이 $&Delta; \mathbf{x}$의 극소가 된다.</b>
</p>

\begin{equation}
\begin{aligned}
    \frac{\partial \mathbf{E}(\mathbf{x}+\Delta \mathbf{x})}{\partial \Delta \mathbf{x}}  \simeq 2\mathbf{b} + 2\mathbf{H} \Delta \mathbf{x} = 0
\end{aligned}
\end{equation}
<p>
이를 정리하면 다음과 같은 공식이 도출된다.
</p>

\begin{equation}
\begin{aligned}
    \mathbf{H}\Delta \mathbf{x} = - \mathbf{b}
\end{aligned}
\end{equation}
<p>
이렇게 구한 $&Delta; \mathbf{x}= -\mathbf{H}^{-1}\mathbf{b}$를 $\mathbf{x}$에 업데이트해준다.
</p>

\begin{equation}
\begin{aligned}
        \mathbf{x} \leftarrow \mathbf{x} + \Delta \mathbf{x}
\end{aligned}
\end{equation}
<p>
지금까지 과정을 반복적(iterative)으로 수행하는 알고리즘을 Gauss-Newton 방법이라고 한다. <b>정리하면, PGO에서 정의한 공식은 비선형항을 포함하므로 closed form solution이 존재하지 않고 따라서 지금까지 설명한 GN 방법을 통해 반복적으로 최적화된다.</b> LM 방법은 GN 방법과 비교했을 때 전체적인 프로세스는 동일하나 증분량을 구하는 공식에서 damping factor $&lambda;$항이 추가된다.
</p>

\begin{equation}
\begin{aligned}
&amp; \text{(GN) }\mathbf{H}\Delta \mathbf{x} = - \mathbf{b} \\
&amp; \text{(LM) }(\mathbf{H} + \lambda \mathbf{I})\Delta \mathbf{x} = - \mathbf{b}
\end{aligned}
\end{equation}
</div>
</div>

<div id="outline-container-org510ea51" class="outline-3">
<h3 id="org510ea51"><span class="section-number-3">3.2</span> Graphical explain of PGO</h3>
<div class="outline-text-3" id="text-3-2">
<p>
PGO의 과정을 그림으로 순차적으로 나타내면 다음과 같다. 자율주행차량이 주행을 하면서 Loop Closing이 발생하는 상황을 예로 들어서 PGO를 설명해보자. <b>해당 시나리오에서는 Loop Closing이 발생하여 기존에 누적된 에러를 제거하기 위해 PGO를 사용했다고 가정한다.</b>
</p>


<figure>
<img src="/pictures/200908/04.png" alt="04.png" align="center" width="800px">

</figure>
<hr>

<figure>
<img src="/pictures/200908/05.png" alt="05.png" align="center" width="800px">

</figure>

<hr>

<figure>
<img src="/pictures/200908/06.png" alt="06.png" align="center" width="800px">

</figure>

<hr>

<figure>
<img src="/pictures/200908/07.png" alt="07.png" align="center" width="800px">

</figure>

<hr>

<figure>
<img src="/pictures/200908/08.png" alt="08.png" align="center" width="800px">

</figure>

<hr>

<figure>
<img src="/pictures/200908/09.png" alt="09.png" align="center" width="800px">

</figure>

<p>
자율주행차량은 위와 같이 센서의 입력에 따라 순차적으로 Pose 노드를 생성하며 주행한다. 이 때는 Front-end 알고리즘만 작동한다.
</p>

<hr>

<figure>
<img src="/pictures/200908/10.png" alt="10.png" align="center" width="800px">

</figure>

<hr>

<figure>
<img src="/pictures/200908/11.png" alt="11.png" align="center" width="800px">

</figure>

<p>
Loop Detection 알고리즘에 의해 Loop를 발견했다고 가정해보자. Loop가 발견된 순간 기존의 노드와 엣지는 전부 예측값으로 변경된다. ($\mathbf{z} \rightarrow \hat{\mathbf{z}}$)
</p>

<hr>

<figure>
<img src="/pictures/200908/12.png" alt="12.png" align="center" width="800px">

</figure>

<p>
관측값을 계산한다. LiDAR SLAM의 경우 GICP 같은 알고리즘을 사용하여 새로운 $\mathbf{z}_{ij}$를 계산한다.
</p>

<hr>

<figure>
<img src="/pictures/200908/13.png" alt="13.png" align="center" width="800px">

</figure>

<p>
관측값과 예측값의 차이를 에러 $\mathbf{e}_{ij}$로 설정한다. Pose graph에서 관측값과 예측값은 상대포즈(Relative Pose)로 나타내므로 둘의 차이는 $\mathbf{z}_{ij}-\hat{\mathbf{z}}_{ij}$이 아닌 실제로는 $\mathbf{z}^{-1}_{ij}\hat{\mathbf{z}}_{ij}$로 나타낸다.
</p>

\begin{equation}
\begin{aligned}
\mathbf{e}_{ij} = \mathbf{z}^{-1}_{ij}\hat{\mathbf{z}}_{ij}
\end{aligned}
\end{equation}
<hr>

<figure>
<img src="/pictures/200908/14.png" alt="14.png" align="center" width="800px">

</figure>

<p>
모든 노드들의 에러가 최소화되는 차량의 포즈 $\mathbf{x}$를 계산한다. 이 때 비선형 최소제곱법(GN, LM)을 통해 반복적으로 에러가 최소가 되는 로봇의 포즈를 업데이트한다. 본 포스팅에서는 최적화 라이브러리로 g2o를 사용하였다. 
</p>
</div>
</div>
</div>

<div id="outline-container-org33ba380" class="outline-2">
<h2 id="org33ba380"><span class="section-number-2">4</span> Code review</h2>
<div class="outline-text-2" id="text-4">
<p>
PGO를 테스트해 볼 수 있는 튜토리얼 예제를 github에 작성하였다. 코드는 <a href="https://github.com/edward0im/pgo_toy_example">해당 링크</a>를 통해 다운로드 및 실행 가능하다. 최적화 라이브러리로 g2o를 사용하였으며 ROS 환경에서 구동할 수 있도록 설정하였다. 보다 자세한 실행 방법은 링크 내에 설명되어 있다.
</p>

<p>
예제는 각 케이스마다 20번씩 최적화를 수행하며 20번이 지난 후에는 랜덤하게 초기화되어 다음 케이스로 넘어간다. 예제를 실행한 결과는 다음과 같다.
</p>


<figure>
<img src="/pictures/200908/intro.gif" alt="intro.gif" align="center" width="800px">

</figure>

<p>
예제의 상황은 Front-end에서 Loop Closing이 발생한 상황부터 시작한다.
</p>


<figure>
<img src="/pictures/200909/01.png" alt="01.png" align="center" width="800px">

</figure>

<p>
Loop Closing이 발생하면 Front-end에서 GICP를 통해 새로운 관측값 $\mathbf{z}_{ij}$를 구하고 기존의 값들은 예측값 $\hat{\mathbf{z}}_{ij}$으로 전환된다. 다음으로 관측값과 예측값을 Back-end로 전달한다.
</p>


<figure>
<img src="/pictures/200909/02.png" alt="02.png" align="center" width="800px">

</figure>

<p>
Back-end에서 관측값과 예측값의 차이를 $\mathbf{e}_{ij}$로 설정하여 이전 섹션에서 설명한 GN, LM과 같은 방법을 통해 20번씩 최적화를 수행한다. 실제 SLAM 알고리즘에서 20번 최적화는 순식간에 완료되지만 시각화를 위해 천천히 최적화하도록 코드를 작성하였다.
</p>


<figure>
<img src="/pictures/200909/03.png" alt="03.png" align="center" width="800px">

</figure>

<div class="org-src-container">
<pre class="src src-c++"><span class="org-constant">PGOToyExample</span>::<span class="org-function-name">PGOToyExample</span>(<span class="org-type">bool</span> <span class="org-variable-name">verbose</span>)
    : vertex_id_(0), verbose_(verbose)
{
  num_poses_ = 15; <span class="org-comment-delimiter">// </span><span class="org-comment">Set number of poses.</span>

  <span class="org-comment-delimiter">// </span><span class="org-comment">Set g2o solver.</span>
  <span class="org-constant">std</span>::<span class="org-type">unique_ptr</span>&lt;<span class="org-constant">g2o</span>::<span class="org-constant">BlockSolver_6_3</span>::LinearSolverType&gt; <span class="org-variable-name">linear_solver</span>;
  linear_solver = <span class="org-constant">g2o</span>::make_unique&lt;<span class="org-constant">g2o</span>::<span class="org-type">LinearSolverDense</span>&lt;<span class="org-constant">g2o</span>::<span class="org-constant">BlockSolver_6_3</span>::PoseMatrixType&gt;&gt;();

  <span class="org-comment-delimiter">// </span><span class="org-comment">use LM method to minimize nonlinear least square.</span>
  <span class="org-constant">g2o</span>::<span class="org-type">OptimizationAlgorithmLevenberg</span>* <span class="org-variable-name">solver</span> =
      <span class="org-keyword">new</span> <span class="org-constant">g2o</span>::<span class="org-type">OptimizationAlgorithmLevenberg</span>(<span class="org-constant">g2o</span>::make_unique&lt;<span class="org-constant">g2o</span>::BlockSolver_6_3&gt;(<span class="org-constant">std</span>::move(linear_solver)));
  solver-&gt;setUserLambdaInit(1);

  optimizer_ = <span class="org-keyword">new</span> <span class="org-constant">g2o</span>::<span class="org-type">SparseOptimizer</span>();
  optimizer_-&gt;setAlgorithm(solver);
}
</pre>
</div>

<p>
보다 자세한 코드 리뷰는 <a href="https://www.facebook.com/groups/slamkr/permalink/1221930924833216/">해당 링크</a>의 자료를 참고하면 된다. 
</p>
</div>
</div>

<div id="outline-container-org1c08706" class="outline-2">
<h2 id="org1c08706"><span class="section-number-2">5</span> References</h2>
<div class="outline-text-2" id="text-5">
<ol class="org-ol">
<li><a href="https://journals.sagepub.com/doi/abs/10.1177/0278364906065387?casa_token=GgYv1_E10lkAAAAA%3Aa2dCyZPksSJUerYbSFzncckAtMAAhGQM2UwCl2oBUPMMfzhhBN0lakSfEGX7ETfRdrPbcTR0qc8aVqE&amp;">Thrun, S. and Montemerlo, M., 2006. The graph SLAM algorithm with applications to large-scale mapping of urban structures. The International Journal of Robotics Research, 25(5-6), pp.403-429.</a></li>
<li><a href="https://www.youtube.com/watch?v=_i8PaekcguA&amp;list=PLubUquiqNQdOTNocmWCSWk9ZaWhV7ubCD">Facebook SLAMKR Online Study Season 1</a></li>
<li><a href="https://youtu.be/wVsfCnyt5jA">Robot Mapping Course - Freiburg University</a></li>
</ol>
</div>
</div>
